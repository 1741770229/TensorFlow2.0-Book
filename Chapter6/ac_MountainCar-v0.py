import gymimport numpy as npimport randomdef policy_function(observation, theta):    weight = np.dot(theta, observation)    # 采用ε贪心（ε-greedy）搜索对环境进行探索    rand_num = random.random()    epsilon = 0.8    if rand_num > epsilon:        # 随机选择一个动作        s = 0        action = random.randint(0, 2)    else:        # 策略函数：y=[e^x-e^(-x)]/[e^x+e^(-x)]        s = (np.exp(weight) - np.exp(-weight)) / (np.exp(weight) + np.exp(-weight))        if s < -0.3:            action = 0  # 施加一个向左的力        elif s > 0.3:            action = 1  # 不施加力        else:            action = 2  # 施加一个向右的力    return s, actiondef actor(env, observation, theta, pre_phi, phi, df_gamma, df_lambda):    # 学习率    alpha = 0.001    while True:        # 根据当前策略选择动作        s, action = policy_function(observation, theta)        pre_observation = observation        # 执行选择的动作并得到反馈信息（新的环境状态、奖励等）        observation, reward, done, info = env.step(action)        # 可视化游戏画面（重绘一帧画面）        env.render()        delta, pre_phi, phi = critic(pre_phi, phi, pre_observation, observation, reward, df_gamma, df_lambda)        # 更新策略函数的参数 theta        theta += alpha * df_lambda * delta * (1 - s * s) * (-pre_observation)        df_lambda *= df_gamma        # 游戏结束后重置环境        if done:            observation = env.reset()def critic(pre_phi, phi, pre_observation, observation, reward, df_gamma, df_lambda):    # 学习率    beta = 0.001    # 计算当前状态的价值    weight = np.dot(phi, observation)    v = 1 / (1 + np.exp(-weight))    # 计算上一状态的价值    pre_weight = np.dot(pre_phi, pre_observation)    pre_v = 1 / (1 + np.exp(-pre_weight))    delta = reward + df_gamma * v - pre_v    pre_phi = phi    # 更新价值函数的参数 phi    phi += beta * df_lambda * delta * pre_v * (1 - pre_v) * (-pre_observation)    return delta, pre_phi, phidef actor_critic(env):    observation = env.reset()    # 随机初始化策略函数和状态价值函数的参数    theta = np.random.rand(2)    phi = np.random.rand(2)    print(type(theta))    pre_phi = phi    # 折扣因子    df_gamma = 0.9    df_lambda = 1    actor(env, observation, theta, pre_phi, phi, df_gamma, df_lambda)if __name__ == "__main__":    # 注册游戏环境 MountainCar-v0    game_env = gym.make('MountainCar-v0')    # 取消限制    game_env = game_env.unwrapped    # 开始学习玩“MountainCar-v0”游戏    actor_critic(game_env)